{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mmt\n",
    "\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtGui, QtCore\n",
    "from pyqtgraph.Point import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def find_nearest(a, a0):\n",
    "    return a[np.abs(a-a0).argmin()]\n",
    "\n",
    "class SDYFile(object):\n",
    "    def __init__(self, sdy_fl):\n",
    "        self.sampling_rate = 200 ###Check this - should be a multiple of 4!! this is only a guess\n",
    "        with open(sdy_fl, 'rb') as sdy_f:\n",
    "            sdy_f.seek(0)\n",
    "            self.file_type = np.fromfile(sdy_f, dtype=np.uint32, count=1)\n",
    "            self.date_time = np.fromfile(sdy_f, dtype=np.uint32, count=2)\n",
    "            self.exam_type = np.fromfile(sdy_f, dtype=np.int32, count=1)\n",
    "            #3=pressure, 4=Flow, 5=Combo\n",
    "            \n",
    "            details = ['last_name',\n",
    "                      'first_name',\n",
    "                      'middle_initial',\n",
    "                      'gender',\n",
    "                      'patient_id',\n",
    "                      'physcian',\n",
    "                      'date_of_birth',\n",
    "                      'procedure',\n",
    "                      'procedure_id',\n",
    "                      'accession',\n",
    "                      'ffr',\n",
    "                      'ffr_suid',\n",
    "                      'refering_physcian',\n",
    "                      'additional_pt_history',\n",
    "                      'ivus_suid',\n",
    "                      'department',\n",
    "                      'institution',\n",
    "                      'cathlab_id']\n",
    "            \n",
    "            pt_details = {}\n",
    "            \n",
    "            for detail in details:\n",
    "                temp = sdy_f.read(512)\n",
    "                pt_details[detail] = temp.decode('utf-16').replace('\\x00', '').strip()\n",
    "            \n",
    "            self.pt_details = pt_details\n",
    "            \n",
    "            temp = np.fromfile(sdy_f, dtype=np.uint16, count=-1)\n",
    "            temp_width = len(temp)/(44+1079) #44 +1079 channels of data - don't ask me why\n",
    "            frame = temp.reshape((temp_width, 44+1079)) #The axis to the right is the one which cycles the fastest through the data\n",
    "            self.frame = frame\n",
    "            self.pd = PressureData(SDYFile.clean(frame[:,(5,7,9,11)].ravel()), sampling_rate=self.sampling_rate) #Yep, this uninterleaves the data a second dime\n",
    "            self.pa = PressureData(SDYFile.clean(frame[:, (16,17,18,19)].ravel()), sampling_rate=self.sampling_rate)\n",
    "            self.ecg = ECGData(SDYFile.clean(frame[:, (24,26,28,30)].ravel()), sampling_rate=self.sampling_rate)\n",
    "            self.flow = FlowData(SDYFile.clean(frame[:,(32,32,33,33)].ravel()), sampling_rate=self.sampling_rate)\n",
    "            self.calc1 = frame[:, (34,34,35,35)].ravel() #Only represented by 2 interleaved channels - duplicate to match sampling rate\n",
    "            self.calc2 = frame[:, (36,36,37,37)].ravel()\n",
    "            self.calc3 = frame[:, (38,38,39,39)].ravel()\n",
    "            \n",
    "            self.delay_pd = 0\n",
    "            self.roi_start = 0\n",
    "            self.roi_end = self.pd.data.shape[0]\n",
    "            \n",
    "    @staticmethod\n",
    "    def clean(data):\n",
    "        data_mean = data.mean()\n",
    "        data_std = data.std()\n",
    "        data[(data>(data_mean+5*data_std))| (data<(data_mean - 5*data_std))] = 0\n",
    "        return(data)\n",
    "    \n",
    "    def process(self, start, end):\n",
    "        self.roi_start = start\n",
    "        self.roi_end = end\n",
    "        self.pa.find_peaks(self.roi_start, self.roi_end)\n",
    "        self.pa.find_valleys(self.roi_start, self.roi_end)\n",
    "        self.pd.find_peaks(self.roi_start, self.roi_end)\n",
    "        self.pa.find_valleys(self.roi_start, self.roi_end)\n",
    "        self.calc_ffr()\n",
    "    \n",
    "    def calc_ffr(self):\n",
    "        \n",
    "        start = self.roi_start\n",
    "        end = self.roi_end\n",
    "        sampling_rate = self.sampling_rate\n",
    "        window = sampling_rate * 10 ##I.e. a 10 second smoother. Check what we should use here\n",
    "        \n",
    "        pa = self.pa.data[start:end]\n",
    "        pd = self.pd.data[start:end]\n",
    "        \n",
    "        pa_mean = scipy.ndimage.generic_filter(pa, np.mean, size=window) #This is slow - find a built in\n",
    "        pd_mean = scipy.ndimage.generic_filter(pd, np.mean, size=window) #This is slow - find a built in\n",
    "        ffr_live = pd_mean / pa_mean\n",
    "        ffr = np.min(ffr_live) #Perhaps use lower 95% CI\n",
    "        \n",
    "        self.pa_mean = pa_mean\n",
    "        self.pd_mean = pd_mean\n",
    "        self.ffr_live = ffr_live\n",
    "        self.ffr = ffr\n",
    "    \n",
    "    def plot_raw(self):\n",
    "        plt.ioff()\n",
    "        plt.plot(self.ecg.data, \"g\")\n",
    "        plt.plot(self.pa.data, \"r\")\n",
    "        plt.plot(self.pd.data, \"b\")\n",
    "        plt.plot(self.calc1)\n",
    "        plt.plot(self.calc2)\n",
    "        plt.plot(self.calc3)\n",
    "        plt.show()\n",
    "        \n",
    "    def update(self):\n",
    "        self.region.setZValue(10)\n",
    "        minX, maxX = region.getRegion()\n",
    "        self.p1.setXRange(minX, maxX, padding=0)    \n",
    "        \n",
    "    def updateRegion(self, window, viewRange):\n",
    "        rgn = viewRange[0]\n",
    "        self.region.setRegion(rgn)\n",
    "        \n",
    "    def mouseMoved(self,evt):\n",
    "        pos = evt[0]  ## using signal proxy turns original arguments into a tuple\n",
    "        if self.p1.sceneBoundingRect().contains(pos):\n",
    "            mousePoint = self.vb.mapSceneToView(pos)\n",
    "            index = int(mousePoint.x())\n",
    "            if index > 0 and index < len(self.data1):\n",
    "                self.label.setText(\"<span style='font-size: 12pt'>x=%0.1f,   <span style='color: red'>y1=%0.1f</span>,   <span style='color: green'>y2=%0.1f</span>\" % (mousePoint.x(), self.data1[index], self.data2[index]))\n",
    "            self.vLine.setPos(mousePoint.x())\n",
    "            self.hLine.setPos(mousePoint.y())\n",
    "        \n",
    "    def pyqtgraph_plot_raw(self):\n",
    "        app = QtGui.QApplication([])\n",
    "        win = pg.GraphicsWindow()\n",
    "        win.setWindowTitle('pyqtgraph example: crosshair')\n",
    "        self.label = pg.LabelItem(justify='right')\n",
    "        win.addItem(self.label)\n",
    "        self.p1 = win.addPlot(row=1, col=0)\n",
    "        self.p2 = win.addPlot(row=2, col=0)\n",
    "        \n",
    "        self.region = pg.LinearRegionItem()\n",
    "        self.region.setZValue(10)\n",
    "        # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this \n",
    "        # item when doing auto-range calculations.\n",
    "        self.p2.addItem(self.region, ignoreBounds=True)\n",
    "        \n",
    "        #pg.dbg()\n",
    "        self.p1.setAutoVisible(y=True)\n",
    "        \n",
    "        \n",
    "        #create numpy arrays\n",
    "        #make the numbers large to show that the xrange shows data from 10000 to all the way 0\n",
    "        self.data1 = 10000 + 15000 * pg.gaussianFilter(np.random.random(size=10000), 10) + 3000 * np.random.random(size=10000)\n",
    "        self.data2 = 15000 + 15000 * pg.gaussianFilter(np.random.random(size=10000), 10) + 3000 * np.random.random(size=10000)\n",
    "        \n",
    "        self.p1.plot(self.data1, pen=\"r\")\n",
    "        self.p1.plot(self.data2, pen=\"g\")\n",
    "        \n",
    "        self.p2.plot(self.data1, pen=\"w\")\n",
    "        \n",
    "        self.region.sigRegionChanged.connect(self.update)\n",
    "        \n",
    "        self.p1.sigRangeChanged.connect(self.updateRegion)\n",
    "        \n",
    "        self.region.setRegion([1000, 2000])\n",
    "        \n",
    "        self.vLine = pg.InfiniteLine(angle=90, movable=False)\n",
    "        self.hLine = pg.InfiniteLine(angle=0, movable=False)\n",
    "        self.p1.addItem(self.vLine, ignoreBounds=True)\n",
    "        self.p1.addItem(self.hLine, ignoreBounds=True)\n",
    "        \n",
    "        self.vb = self.p1.vb\n",
    "        \n",
    "        self.proxy = pg.SignalProxy(self.p1.scene().sigMouseMoved, rateLimit=60, slot=self.mouseMoved)\n",
    "\n",
    "\n",
    "                \n",
    "    def plot_ffr(self):\n",
    "        plt.ioff()\n",
    "        plt.plot(self.pa.data[self.roi_start:self.roi_end], \"r\")\n",
    "        plt.plot(self.pa_mean, \"r\")\n",
    "        plt.plot(self.pa.peaks_x-self.roi_start, self.pa.peaks_y, \"ro\")\n",
    "\n",
    "        plt.plot(self.pd.data[self.roi_start:self.roi_end], \"b\")\n",
    "        plt.plot(self.pd.peaks_x-self.roi_start, self.pd.peaks_y, \"bo\")\n",
    "        plt.plot(self.pd_mean, \"b\")\n",
    "\n",
    "        plt.plot(acq.ffr_live*100, \"g\")\n",
    "        plt.show()\n",
    "        \n",
    "    @property\n",
    "    def segment_xs(self):\n",
    "        return np.arange(self.roi_start, self.roi_end)\n",
    "    \n",
    "    def align(self):\n",
    "        # You could just use the built in correlation, but need to minimise amount of data correlated to speed up\n",
    "        start = self.roi_start\n",
    "        end = self.roi_end\n",
    "        sampling_rate = self.sampling_rate\n",
    "        \n",
    "        window_half = np.min([sampling_rate * 5, end-start])//2\n",
    "        max_delay = sampling_rate //2\n",
    "        \n",
    "        ref_start = end-start//2 - window_half\n",
    "        ref_end = ref_start + 2*window_half\n",
    "        ref_data = self.pa.data[ref_start:ref_end]\n",
    "        \n",
    "        search_delays = np.arange(-max_delay, max_delay)\n",
    "        corrcoef_delays = np.zeros_like(search_delays)\n",
    "        \n",
    "        for i, delay in enumerate(search_delays):\n",
    "            search_data = self.pd.data[ref_start-de]\n",
    "    \n",
    "class PressureData(object):\n",
    "    def __init__(self, data, sampling_rate):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.data = scipy.signal.savgol_filter(data, 31, 5)\n",
    "        \n",
    "    def find_peaks(self, start, end):\n",
    "        #Have to limit the range it as takes ages - dont look at the bits you are not interested in.\n",
    "        #This is my amazing super pressure wave peak finding algorithm.\n",
    "        #I works *exceptionally* well.\n",
    "        #Smooth data (again) then find peaks using continuous wavelet tranform with some optimised test widths.\n",
    "        #This robustly gets you proper peaks, but not the actual peak - as if peak is assymetric is offset.\n",
    "        #Then find local maximum (on a sensible scale) of the original dataset.\n",
    "        #Then iterate through the robust cwt peaks and find the nearest local maximum\n",
    "        #Once you have optimised it for a few traces with a fixed sample rate and noise profile is as solid as a rock.\n",
    "        #Patent Pending Matthew Shun-Shin\n",
    "                \n",
    "        data = self.data[start:end]\n",
    "        data_smooth = scipy.signal.savgol_filter(data, 51, 3)\n",
    "        widths = np.array([40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 225])\n",
    "        \n",
    "        cwt_peaks = scipy.signal.find_peaks_cwt(data_smooth, widths)\n",
    "        relmax_peaks = scipy.signal.argrelmax(data, order=50)[0]\n",
    "        \n",
    "        final_peaks = set()\n",
    "        \n",
    "        for peak in cwt_peaks:\n",
    "            final_peaks.add(find_nearest(relmax_peaks, peak))\n",
    "        \n",
    "        self.peaks_x = np.array(list(final_peaks)) + start\n",
    "        \n",
    "    def find_valleys(self, start, end):\n",
    "        #Have to limit the range it as takes ages - dont look at the bits you are not interested in.\n",
    "        #This is my amazing super pressure wave peak finding algorithm.\n",
    "        #I works *exceptionally* well.\n",
    "        #Smooth data (again) then find peaks using continuous wavelet tranform with some optimised test widths.\n",
    "        #This robustly gets you proper peaks, but not the actual peak - as if peak is assymetric is offset.\n",
    "        #Then find local maximum (on a sensible scale) of the original dataset.\n",
    "        #Then iterate through the robust cwt peaks and find the nearest local maximum\n",
    "        #Once you have optimised it for a few traces with a fixed sample rate and noise profile is as solid as a rock.\n",
    "        #Patent Pending Matthew Shun-Shin\n",
    "                \n",
    "        data = -self.data[start:end]\n",
    "        data_smooth = scipy.signal.savgol_filter(data, 51, 3)\n",
    "        widths = np.array([40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200, 225])\n",
    "        \n",
    "        cwt_valleys = scipy.signal.find_peaks_cwt(data_smooth, widths)\n",
    "        relmax_valleys = scipy.signal.argrelmax(data, order=50)[0]\n",
    "        \n",
    "        final_valleys = set()\n",
    "        \n",
    "        for valley in cwt_valleys:\n",
    "            final_valleys.add(find_nearest(relmax_valleys, valley))\n",
    "        \n",
    "        self.valleys_x = np.array(list(final_valleys)) + start\n",
    "        \n",
    "    @property\n",
    "    def peaks_y(self):\n",
    "        return self.data[self.peaks_x]\n",
    "    \n",
    "    @property\n",
    "    def valleys_y(self):\n",
    "        return self.data[self.valleys_x]\n",
    "    \n",
    "class FlowData(object):\n",
    "    def __init__(self, data, sampling_rate):\n",
    "        self.data = data\n",
    "        self.sampling_rate = sampling_rate\n",
    "    \n",
    "    def find_peaks(self):\n",
    "        #Put flow detection algorithm here\n",
    "        self.peaks_x = [1]\n",
    "        \n",
    "    @property\n",
    "    def peaks_y(self):\n",
    "        return self.data[self.peaks_x]\n",
    "    \n",
    "class ECGData(object):\n",
    "    def __init__(self, data, sampling_rate):\n",
    "        self.data = data\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def find_peaks(self, start, end):\n",
    "        #Put ecg detection algorithm here\n",
    "        #Put pan tompkinson.\n",
    "        #I.e.\n",
    "        #Filer - band pass\n",
    "        #Square Data\n",
    "        #Sliding window integration\n",
    "        #Then shift it back as this pushs the peaks on\n",
    "        #Then simple peak detection\n",
    "        #With heristics.\n",
    "        self.peaks_x = [1]\n",
    "        \n",
    "    @property\n",
    "    def peaks_y(self):\n",
    "        return self.data[self.peaks_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'exec_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9bb0a7c1fefd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#acq.plot_raw()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mQtGui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQApplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetGraphicsSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raster\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mQtGui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQApplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'exec_'"
     ]
    }
   ],
   "source": [
    "#sdy_fl = \"../../IFR Downloaded/19-08-15/CMStudy_2015_07_21_142138.sdy\"\n",
    "#acq = SDYFile(sdy_fl)\n",
    "\n",
    "#acq.pt_details\n",
    "\n",
    "#acq.plot_raw()\n",
    "QtGui.QApplication.setGraphicsSystem(\"raster\")\n",
    "QtGui.QApplication.instance().exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accession': u'',\n",
       " 'additional_pt_history': u'',\n",
       " 'cathlab_id': u'\\u0b44x',\n",
       " 'date_of_birth': u'',\n",
       " 'department': u'',\n",
       " 'ffr': u'',\n",
       " 'ffr_suid': u'',\n",
       " 'first_name': u'',\n",
       " 'gender': u'',\n",
       " 'institution': u'',\n",
       " 'ivus_suid': u'',\n",
       " 'last_name': u'',\n",
       " 'middle_initial': u'',\n",
       " 'patient_id': u'3288021857',\n",
       " 'physcian': u'',\n",
       " 'procedure': u'',\n",
       " 'procedure_id': u'',\n",
       " 'refering_physcian': u''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq.pt_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This shows the file\n",
    "%matplotlib qt4\n",
    "acq.plot_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "start = 100\n",
    "end = 30000\n",
    "acq.process(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This shows the peak detection\n",
    "%matplotlib qt4\n",
    "acq.plot_ffr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24167,  6763,  2683, 15997,  6273, 13443, 29315, 18054, 23699,\n",
       "       26772, 12957,  2207,  5808,  1713, 15541, 23222, 17592, 28858,\n",
       "       26306,  1219, 12487, 22728,  5325, 22233, 17115,   735, 25831,\n",
       "       15081, 28395,  4849, 21233, 21747,   244, 12021,  4364, 11540,\n",
       "       14612, 25365, 10008, 16666,  3868, 27933,  9506, 19234,  9008,\n",
       "        7989, 14133, 11063, 24890,  8513, 10570,  3405, 13651, 16213,\n",
       "       24406, 18775, 29536,  7009,  2923,  6511, 18291, 26998, 23928,\n",
       "        2443, 13197,  6034, 15768, 17819, 29085,  1955, 12716, 23470,\n",
       "       26543,  1469, 22975,  5568, 15307, 19405, 17358, 22481, 28626,\n",
       "       26068,  5083,   988, 12258, 21987,   488, 21481, 25594, 16891,\n",
       "       28156,  4610, 11781, 14853, 10251,  4115,  9759, 11296, 14370,\n",
       "        9256, 29744, 25137,  8754,  3635, 16436, 27698, 18998,  8256,\n",
       "       13891, 10821, 24646,  7259,  3165, 18529])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acq.pa.peaks_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14308, 27869, 29022,  1895,  5744, 27634, 14068, 25078, 15479,\n",
       "       16376, 23160, 28791,  8188, 24829,  8447,  5504, 17535, 22913,\n",
       "       18947, 26244, 13829,  1158, 10760, 22665, 24584,  7179,  5261,\n",
       "       22417, 28562, 26007, 24344, 29463, 22170, 21915,   924,  3100,\n",
       "       16158,  2847,   672, 18468, 17061,   424, 12200, 21417, 24106,\n",
       "       25769, 28330,  6448, 20659, 13620, 18229, 11958, 21688, 26939,\n",
       "       16829, 10302,  6207,  3776, 15937, 13380, 11718,  4296, 17992,\n",
       "       28105, 29256, 13133,  4048, 11477,  5974, 14550, 15707, 16605,\n",
       "       19166, 26718,  1376, 12640, 12896, 19297])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq.pa.valleys_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp = scipy.ndimage.generic_filter(acq.pa.data, np.mean, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib qt4\n",
    "plt.plot(temp)\n",
    "plt.plot(acq.pa.data[acq.roi_start:acq.roi_end])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0008220542331612"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq.ffr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
